#PySpark SQL supports reading a Hive table to DataFrame in two ways: 
# SparkSesseion.read.table() method and the SparkSession.sql() statement.

# In order to read a Hive table, you need to create a SparkSession with enableHiveSupport().
# This method is available at pyspark.sql.SparkSession.builder.enableHiveSupport()
# It is used to enable Hive support, including connectivity to a persistent Hive metastore, support for Hive SerDes, and Hive user-defined functions.


from os.path import abspath
from pyspark.sql import SparkSession

#enableHiveSupport() -> enables sparkSession to connect with Hive
#warehouse_location  -> PySpark reads the data from the default Hive warehouse location which is /user/hive/warehouse when you use a Hive cluster.
                   # -> But on local, it reads from the current directory. You can change this behavior, using the spark.sql.warehouse.dir configuration while creating a SparkSession

warehouse_location = abspath('spark-warehouse')   
spark = SparkSession \
    .builder \
    .appName("SparkByExamples.com") \
    .config("spark.sql.warehouse.dir", warehouse_location) \
    .enableHiveSupport() \
    .getOrCreate()


# Read Hive table
df = spark.sql("select * from emp.employee")
df.show()


# Read Hive table
df = spark.read.table("employee")
df.show()

#Save DataFrame as Internal Table from PySpark

sampleDF.write.mode('overwrite') \
    .saveAsTable("emp.employee")
    
 # Save as Hive External table (Use Option)
sampleDF.write.mode(SaveMode.Overwrite)
        .option("path", "/path/to/external/table")
        .saveAsTable("emp.employee")
        
#Using PySpark SQL Temporary View to Save Hive Table       
        
 # Create temporary view
sampleDF.createOrReplaceTempView("sampleView")

# Create a Database CT
spark.sql("CREATE DATABASE IF NOT EXISTS ct")

# Create a Table naming as sampleTable under CT database.
spark.sql("CREATE TABLE ct.sampleTable (id Int, name String, age Int, gender String)")

# Insert into sampleTable using the sampleView. 
spark.sql("INSERT INTO TABLE ct.sampleTable  SELECT * FROM sampleView")

# Lets view the data in the table
spark.sql("SELECT * FROM ct.sampleTable").show()
